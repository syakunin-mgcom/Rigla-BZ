{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b559dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pf.mgcom.ru/task/1433882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe2293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 действие\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a64498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 действие\n",
    "START_DATE = '2024-05-01'\n",
    "END_DATE = '2024-05-06'\n",
    "\n",
    "# BZ Files\n",
    "PATH_AM_BZ_EVENTS = r'D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\AM\\BZ\\Events\\AM_bz_events_01.04-06.05.csv'\n",
    "PATH_AM_BZ_INSTALLS = r'D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\AM\\BZ\\Installs\\AM_bz_installations_01.04-06.05.csv'\n",
    "\n",
    "\n",
    "# Rigla Files\n",
    "PATH_AM_RIGLA_EVENTS = r'D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\AM\\Rigla\\Events\\AM_rigla_events_01.04-06.05.csv'\n",
    "PATH_AM_RIGLA_INSTALLS = r'D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\AM\\Rigla\\Installs\\AM_rigla_installations_01.04-06.05.csv'\n",
    "\n",
    "#OUTPUT\n",
    "PATH_OUTPUT = r'D:\\Work\\Rigla__Bud_Zdorov\\2024-09-12\\Output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8255ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 действие\n",
    "def save_df_to_csv(df, dir_to_save, name, separate_by='\\t', dec=','):\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    file_name = ts + '_' + name + '.csv'\n",
    "    if not os.path.exists(dir_to_save):\n",
    "        os.makedirs(dir_to_save)\n",
    "    csv_path = os.path.join(os.path.normpath(dir_to_save), file_name)\n",
    "    df.to_csv(csv_path, index=False, sep=separate_by, decimal=dec)\n",
    "    print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}: dataFrame saved to {csv_path}\")\n",
    "    return csv_path\n",
    "\n",
    "def print_ts(message):\n",
    "    print(\"{ts}: {message}\".format(ts=datetime.now().strftime('%Y-%m-%d %H:%M:%S'), message=message))\n",
    "    return\n",
    "\n",
    "# Получаем истоники для каждого уникального appmetrica_device_id\n",
    "def get_install_sources(df):\n",
    "    # Приводим время по формату (2024-02-01 00:18:25)\n",
    "    df['install_datetime'] = pd.to_datetime(df['install_datetime'], format='%Y-%m-%d %H:%M:%S')    \n",
    "    \n",
    "    # Берём первый заказ за месяц\n",
    "    group_cols = ['brand', 'publisher_name', 'tracker_name', 'appmetrica_device_id']\n",
    "    filter_df = df.groupby(group_cols, as_index=False, dropna=False).agg({'install_datetime':['min']})\n",
    "    filter_df.columns = group_cols + ['install_datetime']\n",
    "    xdf = df.merge(filter_df, on=list(filter_df.columns), how='inner')\n",
    "    xdf = xdf[list(filter_df.columns) + ['is_reinstallation']]\n",
    "    xdf.rename(columns={'brand':'brand_install'}, inplace=True)\n",
    "  \n",
    "\n",
    "    # Добавляем информацию об органике\n",
    "    xdf['publisher_name'].fillna('organic', inplace=True)  \n",
    "    return xdf\n",
    "\n",
    "# Раскрываем поле с JSON по столбцам\n",
    "def expand_json(xdf, json_field):\n",
    "    df = xdf.copy(deep=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df_json = pd.json_normalize(df[json_field].apply(lambda x: json.loads(x)))\n",
    "    app_events_data = df.join(df_json)    \n",
    "    return app_events_data\n",
    "\n",
    "\n",
    "# Считываем данные, удаляем дубликаты и присваиваем бренд\n",
    "def get_csv_raw_data(csv_file, sep=';', brand=None):\n",
    "    print_ts('Loading CSV - ' + csv_file)  \n",
    "    df = pd.read_csv(csv_file, sep=sep, encoding='utf8', dtype=object)\n",
    "    df.drop_duplicates(inplace=True)    \n",
    "    df['file'] = csv_file\n",
    "    df['brand'] = brand    \n",
    "    print_ts('Done!')\n",
    "    return df\n",
    "\n",
    "# Фильтруем данные по верменным рамкам\n",
    "def filter_data_to_date_bounds(xdf, event_dt_column, start_date, end_date):\n",
    "    print_ts('Checking dates in {0}'.format(event_dt_column))\n",
    "    df = xdf.copy()\n",
    "    df[event_dt_column] = pd.to_datetime(df[event_dt_column], format='%Y-%m-%d %H:%M:%S')\n",
    "    df_events_unfiltered = df.shape[0]\n",
    "    print_ts('Field:{0}, {1} events from {2} to {3}'.format(event_dt_column, \n",
    "                                                            df_events_unfiltered, \n",
    "                                                            df[event_dt_column].min(), \n",
    "                                                            df[event_dt_column].max()))\n",
    "\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1) \n",
    "    df = df[(df[event_dt_column]>=start) & (df[event_dt_column]<end)]\n",
    "\n",
    "    print_ts('Filtering...')    \n",
    "    print_ts('Field:{0}, {1} events from {2} to {3}'.format(event_dt_column, \n",
    "                                                            df.shape[0], \n",
    "                                                            df[event_dt_column].min(), \n",
    "                                                            df[event_dt_column].max()))\n",
    "    print_ts('{0} events filtered'.format(df_events_unfiltered - df.shape[0]))\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Получаем данные AppMetrica\n",
    "def get_am_data(bz_events, bz_installs, rigla_events, rigla_installs):\n",
    "    # Считываем данные\n",
    "    am_events_bz = get_csv_raw_data(bz_events, sep=',', brand = 'budzdorov.ru')\n",
    "    am_installs_bz = get_csv_raw_data(bz_installs, sep=',', brand = 'budzdorov.ru')\n",
    "    am_events_rigla = get_csv_raw_data(rigla_events, sep=',', brand = 'rigla.ru')\n",
    "    am_installs_rigla = get_csv_raw_data(rigla_installs, sep=',', brand = 'rigla.ru')\n",
    "\n",
    "    # Фильтруем данные по верменным рамкам\n",
    "    am_events_bz = filter_data_to_date_bounds(am_events_bz, 'event_datetime', START_DATE, END_DATE)\n",
    "    am_installs_bz = filter_data_to_date_bounds(am_installs_bz, 'install_datetime', START_DATE, END_DATE)\n",
    "    am_events_rigla = filter_data_to_date_bounds(am_events_rigla, 'event_datetime', START_DATE, END_DATE)\n",
    "    am_installs_rigla = filter_data_to_date_bounds(am_installs_rigla, 'install_datetime', START_DATE, END_DATE)\n",
    "    \n",
    "    # Получаем истоники для каждого уникального appmetrica_device_id\n",
    "    print_ts('Получаем истоники для каждого уникального appmetrica_device_id')\n",
    "    bz_install_sources = get_install_sources(am_installs_bz)\n",
    "    rigla_install_sources = get_install_sources(am_installs_rigla)\n",
    "    \n",
    "    # Получаем значения из JSON\n",
    "    print_ts('Получаем значения из JSON')\n",
    "    bz_json = expand_json(am_events_bz, 'event_json')\n",
    "    rigla_json = expand_json(am_events_rigla, 'event_json')\n",
    "    \n",
    "    # Добавляем паблишеров\n",
    "    print_ts('Добавляем паблишеров')\n",
    "    bz_publishers = bz_json.merge(bz_install_sources, how='left', on='appmetrica_device_id')\n",
    "    rigla_publishers = rigla_json.merge(rigla_install_sources, how='left', on='appmetrica_device_id')\n",
    "    \n",
    "    # Объединяем данные\n",
    "    print_ts('Объединяем данные')\n",
    "    df = pd.concat([bz_publishers, rigla_publishers]).reset_index(drop=True)\n",
    "    df['publisher_name'].fillna('PUBLISHER_UNKNOWN', inplace=True)\n",
    "    \n",
    "    df['event_datetime'] = pd.to_datetime(df['event_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['event_date'] = pd.to_datetime(df['event_datetime'].dt.date) \n",
    "    df['event_month'] = df['event_datetime'].dt.to_period('M')\n",
    "    return df\n",
    "\n",
    "# Получаем заказы AM сгруппированные только по минимальной дате заказа в месяце\n",
    "# Вариант, который счиаем корректным\n",
    "def get_am_orders_min_event_datetime(df_orders):\n",
    "    df = df_orders.copy(deep=True)\n",
    "    \n",
    "    # Группируем по бренду, месяцу и устройству\n",
    "    suitable_orders = df.groupby([\n",
    "        'brand',\n",
    "        'event_month',\n",
    "        'appmetrica_device_id'], as_index=False, dropna=False).agg({\n",
    "        'event_datetime':'min'\n",
    "    })\n",
    "    suitable_orders['is_suitable_order_in_month'] = True   \n",
    "    # Добавляем признак подходящего заказа для исходного DF (для возможности последующей проверки)\n",
    "    df = df.merge(suitable_orders, how='left', on=[\n",
    "        'brand',\n",
    "        'event_month',\n",
    "        'appmetrica_device_id',\n",
    "        'event_datetime'\n",
    "    ])    \n",
    "    df['is_suitable_order_in_month'].fillna(False, inplace=True)\n",
    "    \n",
    "    # Берём только подходящие заказы\n",
    "    xdf = df[df['is_suitable_order_in_month']]\n",
    "    xdf.reset_index(inplace=True, drop=True)\n",
    "    return xdf\n",
    "\n",
    "# Создаём структуру папок для удобства\n",
    "def util_create_dirs_adhoc(root):\n",
    "    am_bz_events_folder = os.path.join(root, 'AM','BZ','Events')\n",
    "    am_bz_installs_folder = os.path.join(root, 'AM','BZ','Installs')\n",
    "    am_rigla_events_folder = os.path.join(root, 'AM','Rigla','Events')\n",
    "    am_rigla_installs_folder = os.path.join(root, 'AM','Rigla','Installs')\n",
    "    folders = [am_bz_events_folder, am_bz_installs_folder, am_rigla_events_folder, am_rigla_installs_folder]\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            print_ts(f'Creating {folder}')\n",
    "            os.makedirs(folder)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57b6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 действие\n",
    "util_create_dirs_adhoc(r'C:\\Rigla_BZ\\2024 June\\2024-06-09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c25ebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-13 12:55:32: Loading CSV - D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\AM\\BZ\\Events\\AM_bz_events_01.04-06.05.csv\n",
      "2024-09-13 12:55:43: Done!\n",
      "2024-09-13 12:55:43: Loading CSV - D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\AM\\BZ\\Installs\\AM_bz_installations_01.04-06.05.csv\n",
      "2024-09-13 12:55:50: Done!\n",
      "2024-09-13 12:55:50: Loading CSV - D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\AM\\Rigla\\Events\\AM_rigla_events_01.04-06.05.csv\n",
      "2024-09-13 12:55:57: Done!\n",
      "2024-09-13 12:55:57: Loading CSV - D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\AM\\Rigla\\Installs\\AM_rigla_installations_01.04-06.05.csv\n",
      "2024-09-13 12:56:05: Done!\n",
      "2024-09-13 12:56:05: Checking dates in event_datetime\n",
      "2024-09-13 12:56:06: Field:event_datetime, 651413 events from 2024-04-01 00:00:15 to 2024-05-06 23:59:47\n",
      "2024-09-13 12:56:06: Filtering...\n",
      "2024-09-13 12:56:06: Field:event_datetime, 98009 events from 2024-05-01 00:00:04 to 2024-05-06 23:59:47\n",
      "2024-09-13 12:56:06: 553404 events filtered\n",
      "2024-09-13 12:56:06: Checking dates in install_datetime\n",
      "2024-09-13 12:56:07: Field:install_datetime, 425224 events from 2024-04-01 00:00:04 to 2024-05-06 23:59:29\n",
      "2024-09-13 12:56:07: Filtering...\n",
      "2024-09-13 12:56:07: Field:install_datetime, 113031 events from 2024-05-01 00:00:00 to 2024-05-06 23:59:29\n",
      "2024-09-13 12:56:07: 312193 events filtered\n",
      "2024-09-13 12:56:07: Checking dates in event_datetime\n",
      "2024-09-13 12:56:08: Field:event_datetime, 389276 events from 2024-04-01 00:00:27 to 2024-05-06 23:59:52\n",
      "2024-09-13 12:56:08: Filtering...\n",
      "2024-09-13 12:56:08: Field:event_datetime, 63883 events from 2024-05-01 00:00:09 to 2024-05-06 23:59:52\n",
      "2024-09-13 12:56:08: 325393 events filtered\n",
      "2024-09-13 12:56:08: Checking dates in install_datetime\n",
      "2024-09-13 12:56:09: Field:install_datetime, 501114 events from 2024-04-01 00:00:20 to 2024-05-06 23:59:24\n",
      "2024-09-13 12:56:09: Filtering...\n",
      "2024-09-13 12:56:09: Field:install_datetime, 150412 events from 2024-05-01 00:00:01 to 2024-05-06 23:59:24\n",
      "2024-09-13 12:56:09: 350702 events filtered\n",
      "2024-09-13 12:56:09: Получаем истоники для каждого уникального appmetrica_device_id\n",
      "2024-09-13 12:56:10: Получаем значения из JSON\n",
      "2024-09-13 12:56:13: Добавляем паблишеров\n",
      "2024-09-13 12:56:13: Объединяем данные\n"
     ]
    }
   ],
   "source": [
    "# 5 действие Получаем данные AM и тд\n",
    "am_data = get_am_data(PATH_AM_BZ_EVENTS, PATH_AM_BZ_INSTALLS, PATH_AM_RIGLA_EVENTS, PATH_AM_RIGLA_INSTALLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f11afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Берём заказы с минимальным значением event_datetime\n",
    "am_orders_min_event_datetime = get_am_orders_min_event_datetime(am_data)\n",
    "am_orders_min_event_datetime['am_unique_orders'] = int(1)\n",
    "am_orders_min_event_datetime['is_reinstallation'].fillna('false', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "749e3531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-13 12:56:23: dataFrame saved to D:\\Work\\Rigla__Bud_Zdorov\\2024-09-12\\Output\\2024-09-13_125619_am_orders_for_dwh_matching_2024-05-01__2024-05-06.csv\n"
     ]
    }
   ],
   "source": [
    "result_path = save_df_to_csv(am_orders_min_event_datetime, PATH_OUTPUT, 'am_orders_for_dwh_matching_' + START_DATE + '__' + END_DATE, separate_by=',', dec='.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
