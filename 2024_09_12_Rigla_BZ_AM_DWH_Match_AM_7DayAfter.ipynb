{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b559dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pf.mgcom.ru/task/1433882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe2293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from decimal import Decimal, ROUND_HALF_UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a64498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AM Orders For Matching\n",
    "PATH_AM_ORDERS_FOR_MATCHING = r'D:\\Work\\Rigla__Bud_Zdorov\\2024-09-12\\Output\\2024-09-12_165117_am_orders_for_dwh_matching_2024-05-01__2024-05-06.csv'\n",
    "\n",
    "#DWH перед этим пересохранить файлы двх клиента, изменить источник файла на юникод utf-8 и разделитель - запятая\n",
    "DWH_START_DATE = '2024-05-01'\n",
    "DWH_END_DATE = '2024-05-06'\n",
    "PATH_DWH_BZ = r'D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\DWH\\DWH_orders_bz_01.05-06.05_sep.csv'\n",
    "PATH_DWH_RIGLA = r'D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\DWH\\DWH_orders_rigla_01.05-06.05_sep.csv'\n",
    "\n",
    "#OUTPUT\n",
    "PATH_OUTPUT = r'D:\\Work\\Rigla__Bud_Zdorov\\2024-09-12\\Output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8255ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_csv(df, dir_to_save, name):\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    file_name = ts + '_' + name + '.csv'\n",
    "    if not os.path.exists(dir_to_save):\n",
    "        os.makedirs(dir_to_save)\n",
    "    csv_path = os.path.join(os.path.normpath(dir_to_save), file_name)\n",
    "    df.to_csv(csv_path, index=False, sep=';', decimal=',')\n",
    "    print_ts(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}: Сохранено в файл \\n{csv_path}\")\n",
    "    return\n",
    "\n",
    "def print_ts(message):\n",
    "    print(\"{ts}: {message}\".format(ts=datetime.now().strftime('%Y-%m-%d %H:%M:%S'), message=message))\n",
    "    return\n",
    "\n",
    "# Выставляем флаги условий\n",
    "def set_conditions(xdf):\n",
    "    print_ts('Выставляем флаги условий')\n",
    "    df = xdf.copy(deep=True)\n",
    "    \n",
    "    # Условия\n",
    "    cond_1 = df['dwh_order_id']==df['order_id']\n",
    "    # Используется диапазон дат\n",
    "    cond_2 = (df['dwh_am_diff_days']>=-7) & (df['dwh_am_diff_days']<=0)\n",
    "    cond_3 = df['dwh_order_sum']==df['total']\n",
    "    cond_4 = df['is_reinstallation']=='true'\n",
    "\n",
    "    # DWH совпадает с AM по Order ID\n",
    "    df['dwh_am_order_id_equal'] = np.where(cond_1, 1, 0)\n",
    "\n",
    "    # DWH совпадает с AM по Order ID и Дате\n",
    "    df['dwh_am_order_id_date_equal'] = np.where(cond_1 & cond_2, 1, 0)\n",
    "\n",
    "    # DWH совпадает с AM по Order ID и Сумме\n",
    "    df['dwh_am_order_id_sum_equal'] = np.where(cond_1 & cond_3, 1, 0)\n",
    "\n",
    "    # DWH совпадает с AM по Order ID, Дате и Сумме\n",
    "    df['dwh_am_order_id_date_sum_equal'] = np.where(cond_1 & cond_2 & cond_3, 1, 0)\n",
    "    \n",
    "    df['am_is_reinstallation'] = np.where(cond_4, 1, 0)\n",
    "    df['dwh_am_order_id_equal__am_is_reinstallation'] = np.where(cond_1 & cond_4, 1, 0)\n",
    "    df['dwh_am_order_id_date_equal__am_is_reinstallation'] = np.where(cond_1 & cond_2 & cond_4, 1, 0)\n",
    "    df['dwh_am_order_id_sum_equal__am_is_reinstallation'] = np.where(cond_1 & cond_3 & cond_4, 1, 0)\n",
    "    df['dwh_am_order_id_date_sum_equal__am_is_reinstallation'] = np.where(cond_1 & cond_2 & cond_3 & cond_4, 1, 0)\n",
    "    print_ts('OK!')\n",
    "    print()\n",
    "    return df\n",
    "\n",
    "def try_decimal(x):    \n",
    "    try:\n",
    "        y = Decimal(x)\n",
    "    except:\n",
    "        y = Decimal('0')\n",
    "    return y     \n",
    "\n",
    "# Наивная валидация датф по формату и году\n",
    "def validate_dates(xdate, date_format):\n",
    "    try:\n",
    "        date = datetime.strptime(xdate, date_format)\n",
    "        valid = True if date.year == 2024 else False\n",
    "    except:\n",
    "        valid = False\n",
    "    return valid\n",
    "\n",
    "# Подготавливаем данные DWH\n",
    "def dwh_data_prep_adhoc(xdf, date_format):\n",
    "    df = xdf.copy()\n",
    "    df['date_valid'] = df['create_date'].apply(lambda x: validate_dates(x, date_format))\n",
    "    if(not df['date_valid'].values.all()):\n",
    "        incorrect_count = df[~df['date_valid']].shape[0]\n",
    "        print_ts(f'Не все даты прошли проверку. Будет удалено {incorrect_count} записей.')\n",
    "        save_df_to_csv(df[~df['date_valid']], PATH_OUTPUT, f'incorrect_dates__{incorrect_count}')\n",
    "        df = df[df['date_valid']]\n",
    "        \n",
    "    df['dwh_order_create_date'] = pd.to_datetime(df['create_date'], format=date_format)        \n",
    "    df['number_brand'] = df['number'].str.split('/', expand=True)[0]\n",
    "    df['dwh_order_id'] = df['number'].str.split('/', expand=True)[1]\n",
    "    df['dwh_order_sum'] = df['order_sum'].fillna('0')\n",
    "    df['dwh_order_sum'] = df['dwh_order_sum'].apply(lambda x: try_decimal(x))    \n",
    "    df.drop_duplicates(ignore_index=True, inplace=True)\n",
    "    brand_cond_v = [\n",
    "        df['site_name'].str.contains('budzdorov'),\n",
    "        df['site_name'].str.contains('rigla')\n",
    "    ]\n",
    "    brand_choises = ['budzdorov.ru', 'rigla.ru']\n",
    "    df['dwh_brand'] = np.select(brand_cond_v, brand_choises, default=None)\n",
    "    cols_to_use = [\n",
    "        'dwh_brand',\n",
    "        'dwh_order_create_date',\n",
    "        'dwh_order_id',\n",
    "        'dwh_order_sum'\n",
    "    ]\n",
    "    df = df[cols_to_use]\n",
    "    return df\n",
    "\n",
    "# Получаем данные AM (заказы для метчинга)\n",
    "def get_am_data_adhoc(path):\n",
    "    print_ts(f'Получаем данные AM из CSV \\n{path}')\n",
    "    df = pd.read_csv(path, dtype=object)\n",
    "    df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    # df['event_date'] = pd.to_datetime(df['event_date'], format='%Y-%m-%d %H:%M:%S\n",
    "    df['event_date'] = pd.to_datetime(df['event_date'], format='%Y-%m-%d')\n",
    "    df['event_datetime'] = pd.to_datetime(df['event_date'], format='%Y-%m-%d %H:%M:%S')\n",
    "    total_events = df.shape[0]\n",
    "    print_ts(f'Всего событий AM: {total_events}')\n",
    "    print_ts('OK!')\n",
    "    print()\n",
    "    return df\n",
    "\n",
    "# Получаем данные DWH\n",
    "def get_dwh_data_adhoc(path_bz, path_rigla):\n",
    "    print_ts('Получаем данные DWH')\n",
    "\n",
    "    print_ts('Получаем данные BZ\\n' + path_bz)\n",
    "    dwh_data_bz_raw = pd.read_csv(path_bz, sep=';', dtype=object)\n",
    "    print_ts('Подготавливаем данные BZ')\n",
    "    dwh_data_bz = dwh_data_prep_adhoc(dwh_data_bz_raw, \"%Y-%m-%d\")\n",
    "    bz_events = dwh_data_bz.shape[0]\n",
    "    print_ts(f'Всего событий BZ: {bz_events}')\n",
    "    print()\n",
    "\n",
    "\n",
    "    print_ts('Получаем данные Rigla\\n' + path_rigla)\n",
    "    dwh_data_rigla_raw = pd.read_csv(path_rigla, sep=';', dtype=object)\n",
    "    print_ts('Подготавливаем данные Rigla')\n",
    "    dwh_data_rigla = dwh_data_prep_adhoc(dwh_data_rigla_raw, \"%Y-%m-%d\")\n",
    "    rigla_events = dwh_data_rigla.shape[0]\n",
    "    print_ts(f'Всего событий Rigla: {rigla_events}')\n",
    "    print()\n",
    "\n",
    "    # Объединяем данные\n",
    "    dwh_data = pd.concat([dwh_data_bz, dwh_data_rigla])\n",
    "    print_ts(f'Строк данных DWH: {dwh_data.shape[0]}')\n",
    "    count_of_bz_rigla_unique = dwh_data[['dwh_brand','dwh_order_id']].drop_duplicates().shape[0]\n",
    "    print_ts(f'Уникальных заказов: {count_of_bz_rigla_unique}')    \n",
    "\n",
    "    df = dwh_data[(dwh_data['dwh_order_create_date']>=DWH_START_DATE) & (dwh_data['dwh_order_create_date']<=DWH_END_DATE)]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print_ts('Всего записей DWH: {0}'.format(dwh_data.shape[0]))\n",
    "    print_ts('Отфильтровано по дате: {0}'.format(dwh_data.shape[0] - df.shape[0]))\n",
    "    print_ts('Использовано для отчётного периода записей: {0}'.format(df.shape[0]))\n",
    "    print_ts('')\n",
    "    print(df['dwh_order_create_date'].agg(['min','max'])) \n",
    "    print()\n",
    "    return df\n",
    "\n",
    "# Метчим данные: к данным AM привязываем DWH\n",
    "def get_am_dwh_joined_data(am_data, dwh_data):\n",
    "    print_ts('Метчим данные - к данным AM привязываем DWH')\n",
    "    am_dwh_orders = am_data.merge(dwh_data, how='left', left_on=['order_id','brand'], right_on=['dwh_order_id','dwh_brand'])\n",
    "    am_dwh_orders['am_unique'] = 1    \n",
    "    \n",
    "    # Добавляем разницу в днях\n",
    "    am_dwh_orders['dwh_am_diff_days'] = (am_dwh_orders['dwh_order_create_date'] - am_dwh_orders['event_date']).dt.days\n",
    "    \n",
    "    # Убираем лишние колонки\n",
    "    useful_columns = [\n",
    "        'am_unique',\n",
    "        'dwh_order_create_date', \n",
    "        'dwh_order_id',\n",
    "        'dwh_order_sum', \n",
    "        'dwh_brand', \n",
    "        'event_name', \n",
    "        'event_json',\n",
    "        'event_datetime', \n",
    "        'city', \n",
    "        'appmetrica_device_id',\n",
    "        'brand', \n",
    "        'order_id', \n",
    "        'total', \n",
    "        'publisher_name',\n",
    "        'tracker_name',\n",
    "        'is_reinstallation',\n",
    "        'event_date',\n",
    "        'event_month', \n",
    "        'dwh_am_diff_days'\n",
    "    ]\n",
    "    df = am_dwh_orders[useful_columns].copy()\n",
    "    df['total'] = df['total'].apply(lambda x: Decimal(x))\n",
    "    df['dwh_order_sum'] = df['dwh_order_sum'].apply(lambda x: Decimal(x))\n",
    "    \n",
    "    # Добавляем столбец с разницей по суммам\n",
    "    df['dwh_am_sum_diff'] = df['dwh_order_sum'] - df['total']    \n",
    "    \n",
    "    print_ts('OK!')\n",
    "    print()\n",
    "    return df\n",
    "\n",
    "# Округляем суммы по следующему правилу:\n",
    "# сверка по суммам не учитывает копейки и округляется до 10х, т.е. если сумма 182.50 руб. , она приравнивается к сумме 180 руб.\n",
    "# если сумма 189 руб. , она приравнивается к сумме 190 руб. \n",
    "def round_x_half_up(x):\n",
    "    x = Decimal(x)\n",
    "    if not x.is_nan():        \n",
    "        x = (x / 10).quantize(Decimal('0'), ROUND_HALF_UP) * 10\n",
    "    return x\n",
    "\n",
    "def modify_totals(xdf):\n",
    "    df = xdf.copy(deep=True)\n",
    "    df['dwh_order_sum_original'] = df['dwh_order_sum']\n",
    "    df['total_original'] = df['total']\n",
    "    df['total'] = df['total_original'].apply(lambda x: round_x_half_up(x))\n",
    "    df['dwh_order_sum'] = df['dwh_order_sum_original'].apply(lambda x: round_x_half_up(x))    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Получаем данные AM (заказы для метчинга)\n",
    "    am_data_first_orders = get_am_data_adhoc(PATH_AM_ORDERS_FOR_MATCHING)   \n",
    "    \n",
    "    # Получаем данные DWH\n",
    "    dwh_data_subset = get_dwh_data_adhoc(PATH_DWH_BZ, PATH_DWH_RIGLA)    \n",
    "    \n",
    "    # Метчим данные: к данным AM привязываем DWH\n",
    "    am_dwh_orders_short = get_am_dwh_joined_data(am_data_first_orders, dwh_data_subset)    \n",
    "\n",
    "    # Округляем тоталы\n",
    "    am_dwh_orders_short = modify_totals(am_dwh_orders_short)    \n",
    "    \n",
    "    # Выставляем флаги условий\n",
    "    task_conds_df = set_conditions(am_dwh_orders_short)    \n",
    "    \n",
    "    use_columns = [\n",
    "        'am_unique','brand', 'publisher_name','event_month',\n",
    "        'dwh_am_diff_days', 'dwh_am_order_id_equal',\n",
    "        'dwh_am_order_id_date_equal', 'dwh_am_order_id_sum_equal',\n",
    "        'dwh_am_order_id_date_sum_equal', 'am_is_reinstallation',\n",
    "        'dwh_am_order_id_equal__am_is_reinstallation',\n",
    "        'dwh_am_order_id_date_equal__am_is_reinstallation',\n",
    "        'dwh_am_order_id_sum_equal__am_is_reinstallation',\n",
    "        'dwh_am_order_id_date_sum_equal__am_is_reinstallation']\n",
    "    xdf = task_conds_df[use_columns].copy()    \n",
    "\n",
    "    # Делаем сводную\n",
    "    task_conds_df_sum = xdf.groupby(['event_month', 'brand', 'publisher_name'], as_index=False, dropna=False).sum()\n",
    "    task_conds_df_sum.drop(['dwh_am_diff_days'], axis=1, inplace=True)    \n",
    "    \n",
    "    # Сохраняем полученные данные\n",
    "    print_ts('Сохраняем полученные данные.')\n",
    "    save_df_to_csv(task_conds_df, PATH_OUTPUT, 'task_conds')\n",
    "    save_df_to_csv(task_conds_df_sum, PATH_OUTPUT, 'task_conds_agg')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2be5d5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-12 19:03:16: Получаем данные AM из CSV \n",
      "D:\\Work\\Rigla__Bud_Zdorov\\2024-09-12\\Output\\2024-09-12_165117_am_orders_for_dwh_matching_2024-05-01__2024-05-06.csv\n",
      "2024-09-12 19:03:19: Всего событий AM: 121538\n",
      "2024-09-12 19:03:19: OK!\n",
      "\n",
      "2024-09-12 19:03:19: Получаем данные DWH\n",
      "2024-09-12 19:03:19: Получаем данные BZ\n",
      "D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\DWH\\DWH_orders_bz_01.05-06.05_sep.csv\n",
      "2024-09-12 19:03:19: Подготавливаем данные BZ\n",
      "2024-09-12 19:03:21: Всего событий BZ: 124044\n",
      "\n",
      "2024-09-12 19:03:21: Получаем данные Rigla\n",
      "D:\\Work\\Rigla__Bud_Zdorov\\2024-05-07\\DWH\\DWH_orders_rigla_01.05-06.05_sep.csv\n",
      "2024-09-12 19:03:21: Подготавливаем данные Rigla\n",
      "2024-09-12 19:03:22: Всего событий Rigla: 74978\n",
      "\n",
      "2024-09-12 19:03:22: Строк данных DWH: 199022\n",
      "2024-09-12 19:03:22: Уникальных заказов: 199019\n",
      "2024-09-12 19:03:23: Всего записей DWH: 199022\n",
      "2024-09-12 19:03:23: Отфильтровано по дате: 0\n",
      "2024-09-12 19:03:23: Использовано для отчётного периода записей: 199022\n",
      "2024-09-12 19:03:23: \n",
      "min   2024-05-01\n",
      "max   2024-05-06\n",
      "Name: dwh_order_create_date, dtype: datetime64[ns]\n",
      "\n",
      "2024-09-12 19:03:23: Метчим данные - к данным AM привязываем DWH\n",
      "2024-09-12 19:03:23: OK!\n",
      "\n",
      "2024-09-12 19:03:24: Выставляем флаги условий\n",
      "2024-09-12 19:03:24: OK!\n",
      "\n",
      "2024-09-12 19:03:24: Сохраняем полученные данные.\n",
      "2024-09-12 19:03:28: 2024-09-12 19:03:28: Сохранено в файл \n",
      "D:\\Work\\Rigla__Bud_Zdorov\\2024-09-12\\Output\\2024-09-12_190324_task_conds.csv\n",
      "2024-09-12 19:03:28: 2024-09-12 19:03:28: Сохранено в файл \n",
      "D:\\Work\\Rigla__Bud_Zdorov\\2024-09-12\\Output\\2024-09-12_190328_task_conds_agg.csv\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "# Получаем сводку\n",
    "#######################################\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
